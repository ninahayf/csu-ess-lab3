
---
title: "Lab 3: COVID-19"
subtitle: 'Ecosystem Science and Sustainability 330'
author: 
  - name: "ninahayf.github.io"
    email: "ninahayf@colostate.edu"
format:
  html: 
  self-contained: true
---

# Question 1: Public Data 

-   How does easy access to historical and real-time environmental data shape our understanding of climate trends, resource management, and public health?

This easy access can help us view changes between historical and current climate trends. It can help us look back to see where we went wrong and where we went right. We can also use previous data to help predict future issues or trends

-   What happens when this data disappears or becomes inaccessible?

Losing this data could cause us to be unaware of what has already happened and make it extremely difficult to recognize trends and predict future climate and resource conflicts. 

# Question 2: Daily Summary

Step 1:

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
# Install required packages if not already installed
required_packages <- c("tidyverse", "flextable", "zoo")
new_packages <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]

if (length(new_packages) > 0) {
  install.packages(new_packages)
}

# Load libraries
library(tidyverse) # Data wrangling and visualization
library(flextable) # Make nice tables
library(zoo)       # Rolling averages
```

```{r}
library(tidyverse); library(flextable)
data_url <- 'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv'
data <- read_csv(data_url, show_col_types = FALSE) %>%
  mutate(date = as.Date(date))
```

```{r}
glimpse(data) # Quick look at the structure 
head(data)    # View the first few rows 
dim(data)     # See number of rows and columns
```

Step 2: 

```{r}
# Create a date object
my.date <- as.Date("2022-02-01")

#Create a character object for the state
my.state <- "Colorado"

# Check their types 
class(my.date)  # Should return "Date"
class(my.state) # Should return "character"
```

Step 3:

```{r data-processing, message=FALSE, warning=FALSE}
library(dplyr)

# Filter the dataset to only include Colorado
co_data <- data %>%
  filter(state == "Colorado") %>%
  arrange(county, date) %>% # Ensure data is ordered correctly
  group_by(county) %>%  # Group by county to calculate changes within each county
  mutate(
    new_cases = cases - lag(cases, default = 0),  # Compute daily new cases
    new_deaths = deaths - lag(deaths, default = 0) # Compute daily new deaths
) %>%
  ungroup() # Remove grouping to avoid unintended side effects 

# View the first few rows
head(co_data)
```

Step 4:

```{r tables, message=FALSE, warning=FALSE}
library(dplyr)
library(flextable)  # For formatting tables

# Filter data for the selected date
filtered_data <- co_data %>%
  filter(date == my.date)

# Table 1: Top 5 Counties with the Most Cumulative Cases
top_cumulative_cases <- filtered_data %>%
  arrange(desc(cases)) %>%  # Sort in descending order
  slice_head(n = 5) %>%  # Select top 5 counties
  select(county, cases, deaths)  # Keep relevant columns

# Fortmat Table 1
table1 <- flextable(top_cumulative_cases) %>%
  set_caption("Top 5 Colorado Counties by Cumulative COVID-19 Cases (as of {my.date})") %>%
  colformat_int(j = c("cases", "deaths"), big.mark = ",") %>%
  autofit()

# Table 2: Top 5 Counties with the Most New Cases 
top_new_cases <- filtered_data %>%
  arrange(desc(new_cases)) %>%  # Sort in descending order 
  slice_head(n = 5) %>%  # Select top 5 counties
  select(county, new_cases, new_deaths)  # Keep relevant columns

# Fortmat Table 2
table2 <- flextable(top_new_cases) %>%
  set_caption("Top 5 Colorado Counties by New COVID-19 Cases (as of {my.date})") %>%
  colformat_int(j = c("new_cases", "new_deaths"), big.mark = ",") %>%
  autofit()

# Print tables
table1
table2
```

# Question 3: Normalizing Data

Step 1:

```{r load-population-data, messgae=FALSE, warning=FALSE}
# Load necessary libraries 
library(dplyr)
library(readr)

# Read population data from Census website-
pop_url <- 'https://www2.census.gov/programs-surveys/popest/datasets/2020-2023/counties/totals/co-est2023-alldata.csv'
population_data <- read_csv(pop_url, show_col_types = FALSE)

# Check column names to conform correct naming
colnames(population_data)

# Ensure STATE and COUNTY are formatted correctly for merging with COVID data
population_data <- population_data %>%
  mutate(STATE = sprintf("%02d", as.numeric(STATE)),  # Convert STATE to 2-digit character
    COUNTY = sprintf("%03d", as.numeric(COUNTY)), # Convert COUNTY to 3-digit character
    FIPS = paste0(STATE, COUNTY)  # Create 5-digit FIPS code
) %>%
  select(matches("NAME|2021"), FIPS, COUNTY) %>%  # Keep relevant columns
  filter(COUNTY != "000")  # Remove state-level rows

# Display structure of cleaned data 
glimpse(population_data)
```

Step 2:

```{r population-range, messgae=FALSE, warning=FALSE}
# Find population range in 2021
population_range <- range(population_data$POPESTIMATE2021, na.rm = TRUE)
population_range
```

Step 3:

```{r}
# Load necessary libraries 
library(dplyr)
library(readr)

#Check column names of population_data to verify 'fips' exists
colnames(population_data)

# Ensure 'fips' column exists in population_data 
if(!"fips" %in% colnames(population_data)) {
  # Rename FIPS column (if it exists) to match COVID data 
  if("FIPS" %in% colnames(population_data)) {
    population_data <- population_data %>%
      rename(fips = FIPS)
  } else {
    stop("FIPS column not found in population_data")
  }
}

# Convert fips to character for proper joining
population_data <- population_data %>%
  mutate(fips = as.character(fips))

co_data <- co_data %>%
  mutate(fips = as.character(fips))

# Ensure 'cases' column exists in co_data
if(!"cases" %in% colnames(co_data)) {
  stop("Column 'cases' not found in co_data. Check data loading.")
}

# Join population data with COVID data 
covid_pop_data <- co_data %>%
  left_join(population_data %>% select(fips, POPESTIMATE2021), by = "fips") %>%
  mutate(
    per_capita_cases = cases / POPESTIMATE2021, 
    per_capita_new_cases = new_cases / POPESTIMATE2021,
    per_capita_new_deaths = new_deaths / POPESTIMATE2021
  )

# Inspect the joined dataset
glimpse(covid_pop_data)
dim(covid_pop_data)
```
Step 4:

```{r filter-top-counties, message=FALSE, warning=FALSE}
# Load necessary library 
library(flextable)

covid_pop_data <- covid_pop_data %>%
  mutate(
    per_capita_cases = cases / POPESTIMATE2021,
    per_capita_new_cases = new_cases / POPESTIMATE2021
  )

# Filter for the date 2021-01-01
date_filter <- as.Date("2021-01-01")

top_cumulative_per_capita <- covid_pop_data %>%
  arrange(desc(per_capita_cases)) %>%
  select(county, cases, per_capita_cases) %>%
  head(5)

top_new_per_capita <- covid_pop_data %>%
  filter(date == date_filter) %>%
  arrange(desc(per_capita_new_cases)) %>%
  select(county, new_cases, per_capita_new_cases) %>%
  head(5)
  
# Convert tables to nice format using flextables 
table1 <- top_cumulative_per_capita %>%
  flextable() %>%
  set_caption("Top 5 Counties with Most Cumulative Cases Per Capita on 2021-01-01")

table2 <- top_new_per_capita %>%
  flextable() %>%
  set_caption("Top 5 Counties with Most New Cases Per Capita on 2021-01-01")

# Display tables 
table1
table2
```


# Question 4: Rolling Thresholds
```{r}
rolling_14 <- merged_data %>%
  filter(date >= my.date - 13 & date <= my.date) %>%
  group_by(county) %>%
  summarize(total_new_cases = sum(new_cases, na.rm = TRUE), per_100k = (total_new_cases / first(get(pop_col))) * 100000, .groups = "drop") %>%
  arrange(desc(per_100k))

top_5_rolling <- rolling_14 %>%
  head(5) %>%
  flextable() %>%
  set_caption("Top 5 Counties with Most New Cases in Last 14 Days per 100k")

top_5_rolling
```

# Question 5: Death Toll Analysis
```{r}
co_data <- data %>%
  filter(state == my.state) %>%
  group_by(county) %>%
  arrange(date) %>%
  mutate(new_deaths = deaths - lag(deaths, default = 0)) %>%
  ungroup()

pop_data <- pop_data %>%
  mutate(FIPS = as.character(FIPS)) %>%
  select(FIPS, CTYNAME, DEATHS2021)

merged_data <- co_data %>%
  left_join(pop_data, by = c("fips" = "FIPS")) %>%
  filter(year(date) == 2021)

county_deaths <- merged_data %>%
  group_by(county) %>%
  summarize(total_covid_deaths = sum(new_deaths, na.rm = TRUE),
            total_deaths_2021 = first(`DEATHS2021`), .groups = 'drop') %>%
  mutate(covid_death_percentage = total_covid_deaths / total_deaths_2021 * 100)

high_covid_deaths <- county_deaths %>%
  filter(covid_death_percentage >= 20)

high_covid_deaths

ggplot(high_covid_deaths, aes(x = reorder(county, -covid_death_percentage), y = covid_death_percentage)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +
  labs(title = "Counties in Colorado with COVID Deaths >= 20% of Annual Death Toll",
       x = "County", y = "Percentage of Deaths Attributed to COVID (%)") +
  theme_minimal()
```

# Question 6: Multi-State Analysis 
```{r}
states <- c("New York", "Colorado", "Alabama", "Ohio")
state_data <- data %>%
  filter(state %in% states) %>%
  group_by(state, date) %>%
  summarize(new_cases = sum(cases - lag(cases, default = 0), na.rm = TRUE), .groups = "drop") %>%
  mutate(rolling_avg = rollmean(new_cases, 7, fill = NA))

state_data <- state_data %>%
  filter(!is.na(rolling_avg))

ggplot(state_data, aes(x = date, y = rolling_avg, color = state)) +
  geom_line() +
  labs(title = "7-day Rolling Average of New Cases", y = "New Cases", x = "Date")
```

# Question 7: Spatial Analysis 
```{r}
centroids_url <- 'https://raw.githubusercontent.com/mikejohnson51/csu-ess-330/refs/heads/main/resources/county-centroids.csv'
centroids <- read_csv(centroids_url, show_col_types = FALSE)

spatial_data <- merged_data %>%
  left_join(centroids, by = c("fips" = "fips")) %>%
  group_by(date) %>%
  summarize(weighted_lon = sum(LON * cases, na.rm = TRUE) / sum(cases, na.rm = TRUE), weighted_lat = sum(LAT * cases, na.rm = TRUE) / sum(cases, na.rm = TRUE), .groups = "drop")

ggplot() +
  borders("state", fill = "gray90", colour = "white") +
  geom_point(data = spatial_data, aes(x = weighted_lon, y = weighted_lat, color = date), size = 2) +
  labs(title = "COVID-19 Weighted Mean Center Over Time")
```

# Question 8: Extra Credit: Cases vs. Deaths
```{r}
centroids <- read_csv(centroids_url, show_col_types = FALSE)

spatial_cases <- merged_data %>%
  left_join(centroids, by = c("fips" = "fips")) %>%
  group_by(date) %>%
  summarize(weighted_lon = sum(LON * cases, na.rm = TRUE) / sum(cases, na.rm = TRUE),
            weighted_lat = sum(LAT * cases, na.rm = TRUE) / sum(cases, na.rm = TRUE), .groups = "drop") %>%
  drop_na(weighted_lon, weighted_lat)

spatial_deaths <- merged_data %>%
  left_join(centroids, by = c("fips" = "fips")) %>%
  group_by(date) %>%
  summarize(weighted_lon = sum(LON * deaths, na.rm = TRUE) / sum(deaths, na.rm = TRUE),
            weighted_lat = sum(LAT * deaths, na.rm = TRUE) / sum(deaths, na.rm = TRUE), .groups = "drop") %>%
  drop_na(weighted_lon, weighted_lat)

cases_plot <- ggplot() +
  borders("state", fill = "gray90", colour = "white") +
  geom_point(data = spatial_cases, aes(x = weighted_lon, y = weighted_lat, color = date), size = 2) +
  scale_color_gradient(low = "pink", high = "red") +
  labs(title = "COVID-19 Weighted Mean Center (Cases)")

deaths_plot <- ggplot() +
  borders("state", fill = "gray90", colour = "white") +
  geom_point(data = spatial_deaths, aes(x = weighted_lon, y = weighted_lat, color = date), size = 2) +
  scale_color_gradient(low = "lightblue", high = "navy") +
  labs(title = "COVID-19 Weighted Mean Center (Deaths)")

cases_plot | deaths_plot
```






